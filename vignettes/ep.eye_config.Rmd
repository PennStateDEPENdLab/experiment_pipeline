---
title: "Setting up a YAML Configuration File for an Eyetracking Study in experiment.pipeline"
author: "Nate Hall"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Setting up a YAML Configuration File for an Eyetracking Study in experiment.pipeline}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, include=FALSE}
library(tidyverse)
library(knitr)
# groupdir <- "/proj/mnhallqlab" # on cluster.
groupdir <- "~/ll" # sshfs mounted on local (easier to use markdown knitting functionality)
source(file.path(groupdir, "users/nate/experiment.pipeline/NH_local/setup_envi.R"))
```

# `experiment.pipeline` relies on a single configuration file
The core worker function in the `experiment.pipeline` package for processing eye data on a single subject, (`ep.eye_process_subject.R`) relies entirely on a YAML file that the user sets up prior to processing depending on the structure of the task and the processing procedures desired. 

The YAML file is structured hierarchically, with five fields at the highest level. Additional fields are nested within the high-level fields, which we will explore below. Once the config has been set up and is read in to `experiment.pipeline`, the package's internal environment will have access to all components of the specified configuration in the form of a nested list, which I will show as we go along. 

```{r}
config_path <- file.path(groupdir,"studies/NeuroMAP/s3_data_ep_specs/yaml/SortingMushrooms.yaml")
config <- validate_exp_yaml(config_path)
```

# YAML configuration files: expected fields
Starting at the highest level are the `task`, `runs`, `variable_mapping`, `definitions`, and `blocks` fields. I like to separate these with some sort of break line to denote changes in major sections of the config file. The major action for eyetracking preprocessing happens in `definitions`, and a bit in `blocks`. 

```{r, eval = FALSE}
################################
task: neighborhood
################################
runs: 
################################
variable_mapping:
################################
definitions:
################################
blocks: 
################################
```

These fields are represented in the named list that will be used to process the eye data. Note that at the highest level only `task` and `runs` will have values assigned to them. Leaving colons open at a level of the YAML file either means that there will be subfields with explicit values defined or that the field is to remain empty. 

```{r}
names(config)
```


# High-level information on the task structure: `task`, `runs`, and `variable_mapping`, fields
These three major fields contain high-level information about the task:

## `task`

The `task` field is simply the name of the task that is being processed, in this case the "Sorting Mushrooms Task (Approach-only)" from Huys et. al. (2011, PLOS Comp Bio). This is stored in the ep.eye object's metadata. As things are currently set up, this field has no bearing on the processing itself, but may be useful once batch processing capabilities are fully fleshed out (stay tuned). 
<!-- This is primarily important to specify if you are using the batch processing functionality to process a full battery of tasks but is not used much in the processing scripts themselves. -->
```{r, eval = FALSE}
################################
task: neighborhood
################################
```
This is imported as:
```{r}
config$task # or config[["task"]]
```
<!-- 
## `runs`

The `runs` field has yet to be built in and validated, but the idea here is that multiple exact replicas of a task can be denoted by the user and the config file can be used iteratively on each run without issue.

```{r, eval = FALSE}
################################
runs:
################################
```
This is imported as (empty in this case):
```{r}
config$runs # or config[["runs"]]
```

## `variable_mapping`

The `variable_mapping` field provides a mapping between column names in a $behav dataset (implemented elsewhere) for a subject, mapped to generalized task design constructs that are used within the `experiment_pipeline` nomenclature. Subfields nested within `variable_mapping` are specified as such:

```{r, eval = FALSE}
################################
variable_mapping:
  id: id
  run:
  phase:
  block: block
  trial: trial
  run_trial:
  block_trial: block_trial
  event: event
  condition: condition
################################
```
This is imported as:
```{r}
config$variable_mapping # or config[["variable_mapping"]]
```
Each of these subfields map to a specific task-general construct of interest:

- `id`: Unique identifier for the subject/decision-maker 
- `run`: An exact replication of the entire task procedure used to increase degrees of freedom (from the task fMRI literature). If the task is completed just once this can remain empty (as in this case).
- `phase`: A conceptually distinct phase of the task that produces data that should be validated separately (e.g. unique phases of a Pavlovian-Instrumental Transfer task). 
- `block`: A block of trials. The block may have some characteristics (e.g., mostly incongruent trials in a conflict monitoring task or varying reward/punishment probabilities in a Pavlovian conditioning task), but are validated similarly with respect to the phase. 
- `trial`: A replication unit that is repeated several times in order to achieve a more reliable sample of behavior.
It is important to denote what level of the task hierarchy the trial is ordered with respect to. Examples include:
    - `trial`: Trial number over the entire task, continues to increment across runs and blocks.
    - `run_trial`: Trial within a run, which resets to 1 with every new run.
    - `block_trial`: Trial within a block, which resets to 1 with every new block.
- `event`: A component of a trial that occurs in **time** and  constitutes a perceptible event to the subject (e.g., stimulus onset or offset, onset of an auditory cue, display background changes, etc.). Essentially, an **event** is the most atomic unit of task design and represent momentary changes in task demands.
- `condition`: Experiments also have **design factors** or **conditions** that determine the features of any sub-element in the hierarchy. For example, a 'catch trial' in fMRI can consist of a subset of events within a trial: for example Cue and Anticipation, but no Feedback in a monetary incentive delay task. Or a block may consist of mostly congruent trials, which makes the block a test of a "Mostly congruent" condition. **N.B. consider whether conditions should be specified at different levels of the hierarchy, or if they should remain at the trial-level.**

Importantly, these subfields constitute a task-general hierarchy that will be present regardless of the specifics of the task. An single task sits atop this hierarchy and a single config file will be needed to process each task, with phases, blocks, trials, and events all nested within a task.

# Defining key variables for data processing: `definitions`

This field is where most of the action for processing an eyetracking experiment will happen. The `definitions` field will be grouped according to the data modality (`behav`, `eye`, `phys`). We will focus on `eye` definitions here, directions on implementing `behav` and `phys` definitions can be found [here] and [here].

```{r, eval = FALSE}
################################
definitions:
  # behav: &behav #shared key mapping for behavior across blocks
  #   response: key_pressed
  #   valid: [space, None]
  #   rt: rt
  #   start_time: #key_resp_10.started
  #   end_time: #key_resp_10.stopped
  eye: &eye
    global:
      prefix: "\\d{3}_[[:upper:]]+"
      gen_log: TRUE
      log_dir: '/proj/mnhallqlab/studies/NeuroMAP/s3_preproc/SortingMushrooms/elog'
      save_preproc: TRUE
      preproc_out: '/proj/mnhallqlab/studies/NeuroMAP/s3_preproc/SortingMushrooms/eye'
      return_raw: TRUE 
    initialize:
      expected_edf_fields: ['raw', 'sacc', 'fix', 'blinks', 'msg', 'input', 'button', 'info', 'asc_file', 'edf_file']
      unify_gaze_events: 
        gaze_events: ['sacc', 'fix', 'blink']
        confirm_correspondence: FALSE
      meta_check:
        meta_vars: ['sample.rate', 'model', 'mono', 'pupil.dtype', 'screen.x', 'screen.y', 'version']
        meta_vals: ['1000', 'EyeLink 1000', 'TRUE', 'AREA', '1920', '1080', '4.594']
        recording_time: [1200, 360] # [expected time (seconds), margin of error above and below]
      inherit_btw_ev: # do certain between-trial messages need to be extracted for any reason? If left out, will skip
        calibration_check:
          cal: ["!CAL CALIBRATION HV9"]
          val: ["!CAL VALIDATION HV9"]
        move_to_within:
          str: ["!MODE RECORD CR 1000 2 1 R", "TRIALID", "END_RECORDING", "TRIAL "]
          align_msg: ["", "!MODE RECORD CR 1000 2 1 R", "TRIAL_OUTCOME", "TRIAL_OUTCOME"]
          pre_post: ["post", "pre", "post", "post"]
    msg_parse:
      extract_event_func_path: '/proj/mnhallqlab/studies/NeuroMAP/s3_data_ep_specs/gen_eye_events/gen_SortingMushrooms_eye_events.R'   # if extraction method == "function" pass path to the function here.
      csv_dir_path: '/proj/mnhallqlab/studies/NeuroMAP/s3_data/SortingMushrooms/eye/eye_event_csvs' # if extraction method %in% c("csv", "function")  path to extract or write event csvs to.
      msg_seq: # &msg_seq #decided to comment this out below for the sake of simplicity.
        msg_start: ["!MODE RECORD CR 1000 2 1 R", "TRIALID", "SYNCTIME", "DISPLAY ON"]
        msg_end: [ "TRIAL_OUTCOME ", "TRIAL "]
        eval_middle: TRUE #smoosh certain event-specific (taken from below) messages in between the task-general beginning and end messages.
        ordered: TRUE
    gaze_preproc:
      aoi:
        indicator: ["!V IAREA RECTANGLE"]
        extraction_method: regex
        extract_coords: ["\\d{3,4} \\d{3,4} \\d{3,4} \\d{3,4}"]
        extract_labs: ["[a-z]+$"]
        split_coords: " "
        tag_raw: FALSE #unless there is some strong reason to need super-high resolution on AOI position (moving AOIs, which are not currently supported), this should be FALSE. Default is FALSE if not included in config.
      downsample:
        factor: 20
        method: "mean"
    pupil_preproc:
      blink_corr:
        ms_before: 100
        ms_after: 100
      filter:
        method: "movingavg" #right now only moving average supported
        window_length: 50 #n measurements to lookback while smoothing, gets passed to pracma::movavg. In ms.
      interpolate:
        algor: "spline"
        maxgap: 1000 ### in ms, will use the original sampling frequency and downsampling factor to convert to nmeasurements.
      baseline_correction:
        method: "subtract"
        dur_ms: 100
        center_on: "DISPLAY ON"
      downsample:
        factor: 50
        method: "mean"
    # qa:
    #   gaze:
    #     na:
    #       check: ["raw", "downsample"]
    #       perc: 30
    #       cols: ["xp", "yp"]
    #   pupil:
    #     na:
    #       check: ["downsample"]
    #       perc: 30
    #       cols: ["ps_bc"]
  # phys:
################################
```

## Overview of `definitions$eye` subfields

```{r}
names(config$definitions$eye)
```

- `global`: High-level processing options (whether or not to generate an .elog, path to save preprocessed data to, prefix to append to .elog and preprocessed data, whether or not to save raw eyetracking data). See below for defaults and descriptions. 
- `initialize`: Options utilized as the arguments to `ep.eye_initialize` function. Consider initialization options a form of sanity check on the imported .edf file before any major preprocessing is done.
- `msg_parse`: Off of the SR EyeLink, important events are passed as messages in the `ep.eye$msg` field. However, the meaning of these messages often needs to be validated and integrated into the ep.eye hierarchy by the user in order to make the info contained in the .edf file conceptually meaningful. Subfields of `msg_parse` are utilized in the `ep.eye_parse_events` function.
- `gaze_preproc`
- `pupil_preproc`
- `qa`

## `global`
- `prefix`: A regex to append to the saved .elog and preprocessed data. If supplied, experiment.pipeline will attempt to extract the desired prefix from the basename of the .edf file using `stringr::str_extract`. **Importantly**, if passing a regex in your config file, your regex must be double quoted (rather than single) in order to keep `read_yaml` from appending additional escape characters to your string. If this is left null/empty, will simply use the basename of the .edf file being processed. Defaults to NULL.
- `gen_log`: Logical to determine whether to create an .elog file during processing. If NULL or FALSE will print processing documentation to the console. Defaults to TRUE.
- `log_dir`: Path to the directory to store .elog files. If `log_dir` is NULL (default) and `gen_log` is TRUE will write to working directory. 
- `save_preproc`: Logical to determine whether to attempt to save the preprocessed file. Defaults to TRUE.
- `preproc_out`: Path to directory to store preprocessed ep.eye files. Defaults to NULL, which creates a directory, named "preproc" in working directory.
- `return_raw`: Logical to determine whether or not to return ep.eye$raw data. Defaults to FALSE to cut down on file size unless explicitly requested.

## `initialize_opts`
- `expected_edf_fields`: A character vector of field names that should be included in raw all .edf files. It is suggested to read in a single .edf file using `read_edf` and use `names()` to guide what the expected fields are across participants. Defaults to `['raw', 'sacc', 'fix', 'blinks', 'msg', 'input', 'button', 'info', 'asc_file', 'edf_file']`, which should be auto-generated by `read_edf`. So this can generally be ommitted unless there is an exception to this rule.
- `unify_gaze_events`: Character vector including any subset of `['sacc', 'fix', 'blink']` to perform "gaze event unitization" on. This procedure tags specific "gaze events" with unique identifiers, and appends them to `ep.eye[["raw"]]`, `ep.eye[["sacc"]]`, etc. Defaults to `['sacc', 'fix', 'blink']` to unify all gaze events. This is the more time-consuming piece of `ep.eye_initialize` so if your planned analysis focuses on one type of gaze event over another, selecting just a subset can help cut down on computational time (usually on the order of 2-6 min per subject for a 20 min acquisition).
- `meta_check`: Session metadata taken from the `edf[["info"]]` field (see `expected_edf_fields`) is stored in the ep.eye object, and is appended with additional information throughout the course of ep.eye initialization, message parsing, etc. It is recommended to give an example edf file a quick inspection before batch processing. Subfields of `meta_check` validate that the metadata of a given file does not violate expectations. No default, if this field is NULL or absent, checking metadata will be skipped.
  - `meta_vars`: Field names in `ep.eye[["metadata"]]` to be validated against expected values which are passed in `meta_vals`. Usually, it is good to look at an example .edf file to set expectation across subjects. An example of metavariables to check is: `['sample.rate', 'model', 'mono', 'pupil.dtype', 'screen.x', 'screen.y', 'version']` corresponding to recording session parameters (e.g. sampling rate of the eyetracker in Hz, eyetracker model, binocular vs monocular recording, screen display size in pixels, etc.) that should be the same across subjects. 
  - `meta_vals`: Character vector of matched values to validate with respect to `meta_vars`. If the legnth of `meta_vars` and `meta_vals` do not match, this will generate an error. An example of metavalues to check is: ['1000', 'EyeLink 1000', 'TRUE', 'AREA', '1920', '1080', '4.594']
  - `recording_time`: Numeric vector of length 2 indicating the expected time of the recording session **in seconds** and the margin of error above and below the expected recording time without generating an error. For example, if your task should take approximately 20 mins, with a margin of error of 6 mins, one would pass `[1200, 360]`, which would be interpreted to mean that the `ep.eye[["metadata"]][["recording_time"]]` field should be greater than 840 (14 min) and less than 1560 (26 min).

## `msg_parse` 

**Important:** This stage of setting up your ep.eye config file is important and is probably the stage where the most user interface with the raw data is necessary. In this field, you will specify an expected message structure across events and will use one of a few methods to extract the relevant eyetracker messages which denote things things trials starting and stopping, stimuli being presented, and subject choices. These will be added to the raw data and will eventually be downsampled and interpolated when preprocessing the ep.eye option. Thus, it is higly recommended that you use the `ep.eye_msg_report()` function to extract and examine the messages that get passed to the eyetracker and use this information to guide you at this step. 

- `inherit_btw_ev`: Do certain between-event messages need to be extracted into raw and gaze event data frames? If empty, will skip inheritance of between-event messages. Defaults to NULL.
  - `calibration_check`: Check the between-event messages for calibration and validation messages? This simply checks that messages exist that confirm the type of calibration and validation (e.g. 5- vs 9-point calibration etc.) that were performed on this data. If empty, will skip. Defaults to NULL.
    - `cal`: Calibration message to search for (e.g. `['!CAL CALIBRATION HV9']`) 
    - `val`: Calibration message to search for (e.g. `['!CAL VALIDATION HV9']`) 
  - `move_to_within`: **RECONSIDER DEPRECATING THIS FEATURE**
      - `str`: ["TRIALID", "END_RECORDING", "TRIAL "]
      - `align_msg`: ["!MODE RECORD CR 1000 2 1 R", "TRIAL_OUTCOME", "TRIAL_OUTCOME"]
      - `pre_post`: ["pre", "post", "post"]
- `event_info`:  
  - `extraction_method`: Can be 'csv', 'regex', 'function', or 'data.frame'
  - `extract_event_func_path`: If extraction method == "function" pass path to the function here.
  - `csv_path`: If extraction method %in% c("csv", "function")  path to extract or write event csvs to.
  - `msg_seq`: 
    - `msg_start`: ["!MODE RECORD CR 1000 2 1 R", "TRIALID", "SYNCTIME", "DISPLAY ON"]
    - `msg_end`: [ "TRIAL_RESULT ", "TRIAL "]
    - `eval_middle`: TRUE #smoosh certain event-specific (taken from below) messages in between the task-general beginning and end messages.
    - `ordered`: FALSE -->
